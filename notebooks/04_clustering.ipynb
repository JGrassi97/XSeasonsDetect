{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "from shapely.geometry import mapping\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from models.BRUTAL_X_RCC import XRCC#, XRCC_silhouette\n",
    "from visualization.custom_plots import standard_format, day_of_year_to_date, standard_format_single, plot_seasons_bk_results\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CRPS.CRPS as pscore\n",
    "# arr = np.array([[1,2],[3,4]])\n",
    "# arr_pro = np.array([2,3])\n",
    "\n",
    "# for j in range(arr.shape[1]):\n",
    "#     print(np.array(arr[:,j]).flatten())\n",
    "#     print(arr_pro[j])\n",
    "#     print(pscore(np.array(arr[:,j]).flatten(), arr_pro[j]).compute()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FREE PARAMETERS\n",
    "n_seasons   = 2\n",
    "n_iters     = 28\n",
    "\n",
    "learning_rate   = 5\n",
    "min_len         = 10\n",
    "mode            = 'single'\n",
    "starting_bp     = [50, 330]\n",
    "\n",
    "overwrite_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geopackages with boundaries\n",
    "country_boundary_file   = '../data/preprocessed/external/GADM41_IND.gpkg' \n",
    "world_boundary_file     = '../data/preprocessed/external/GADM41_WORLD_clip.gpkg' \n",
    "hkkh_boundary_file      = '../data/preprocessed/external/HKKH.gpkg'\n",
    "\n",
    "# Path for results\n",
    "results_path_file   = f'../data/results/netcdf_files/clustering_results_{n_seasons}seas_{n_iters}iters_ERA5.nc'\n",
    "results_path_image  = f'../data/results/images/clustering_results_{n_seasons}seas_{n_iters}iters_ERA5.png'\n",
    "\n",
    "if os.path.exists(results_path_file) and overwrite_results:\n",
    "    results_exist = True\n",
    "    print('Results already stored! - Overwriting')\n",
    "\n",
    "if os.path.exists(results_path_file) and not overwrite_results:\n",
    "    results_exist = True\n",
    "    print('Results already stored! - Skipping clustering')\n",
    "\n",
    "# Geodataframes for boudaries - Level 0 is for country boundaries \n",
    "country_boundary    = gpd.read_file(country_boundary_file, layer = 'ADM_ADM_1')\n",
    "world_boundary      = gpd.read_file(world_boundary_file)\n",
    "hkkh_boundary       = gpd.read_file(hkkh_boundary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(results_path_file) or overwrite_results:\n",
    "\n",
    "    dataset_t2m = xr.open_mfdataset(rf'../data/preprocessed/ERA5/2m_temperature/final.nc')['2t'].load()\n",
    "    dataset_tp = xr.open_mfdataset(rf'../data/preprocessed/ERA5/total_precipitation/final.nc').tp.load()\n",
    "    dataset_u100 = xr.open_mfdataset(rf'../data/preprocessed/ERA5/100m_u_wind/final.nc').u100.load()\n",
    "    dataset_v100 = xr.open_mfdataset(rf'../data/preprocessed/ERA5/100m_v_wind/final.nc').v100.load()\n",
    "\n",
    "    dataset_tp['time'] = dataset_t2m['time']\n",
    "    dataset_u100['time'] = dataset_t2m['time']\n",
    "    dataset_v100['time'] = dataset_t2m['time']\n",
    "\n",
    "    datasets = [dataset_tp, dataset_t2m, dataset_u100, dataset_v100]  # Add as many datasets as needed\n",
    "\n",
    "    clustering_params = {\n",
    "        'iters': n_iters,\n",
    "        'n_seas': n_seasons,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_len': min_len,\n",
    "        'mode': mode,\n",
    "        'starting_bp': starting_bp,\n",
    "    }\n",
    "\n",
    "    breakpoints, error_history_da, silhouette_scores_da = XRCC(datasets, **clustering_params)\n",
    "\n",
    "else:\n",
    "    result = xr.open_dataset(results_path_file).__xarray_dataarray_variable__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoints.sel(cluster=3).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "n_days = list(np.arange(0,365,50))\n",
    "\n",
    "x = np.array(list(combinations(n_days, 4))).squeeze()[:,0]\n",
    "y = np.array(list(combinations(n_days, 4))).squeeze()[:,1]\n",
    "\n",
    "\n",
    "# Load country boundary data\n",
    "error_history_da_clip = error_history_da.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "error_history_da_clip.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "\n",
    "error_history_da_clip_IND = error_history_da_clip.rio.clip(country_boundary.geometry.apply(mapping), country_boundary.crs, drop=True)\n",
    "error_history_da_clip_HKK = error_history_da_clip.rio.clip(hkkh_boundary[hkkh_boundary.short_name=='hkk'].geometry.apply(mapping), hkkh_boundary[hkkh_boundary.short_name=='hkk'].crs, drop=True)\n",
    "error_history_da_clip_HIM = error_history_da_clip.rio.clip(hkkh_boundary[hkkh_boundary.short_name=='him'].geometry.apply(mapping), hkkh_boundary[hkkh_boundary.short_name=='him'].crs, drop=True)\n",
    "\n",
    "z_all = error_history_da_clip.mean(['lat', 'lon']).values\n",
    "z_IND = error_history_da_clip_IND.mean(['lat', 'lon']).values\n",
    "z_HKK = error_history_da_clip_HKK.mean(['lat', 'lon']).values\n",
    "z_HIM = error_history_da_clip_HIM.mean(['lat', 'lon']).values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(6,6), sharex=True, sharey=True)\n",
    "ax[0][0].scatter(x, y, c=z_all, cmap='jet')\n",
    "ax[0][0].set_title('All region')\n",
    "ax[0][0].set_xlabel('Day 1')\n",
    "ax[0][0].set_ylabel('Day 2')\n",
    "\n",
    "ax[0][0].set_xlim([0, 365])\n",
    "ax[0][0].set_ylim([0, 365])\n",
    "\n",
    "ax[0][1].scatter(x, y, c=z_IND, cmap='jet')\n",
    "ax[0][1].set_title('India')\n",
    "ax[0][1].set_xlabel('Day 1')\n",
    "ax[0][1].set_ylabel('Day 2')\n",
    "\n",
    "ax[1][0].scatter(x, y, c=z_HKK, cmap='jet')\n",
    "ax[1][0].set_title('HKK')\n",
    "ax[1][0].set_xlabel('Day 1')\n",
    "ax[1][0].set_ylabel('Day 2')\n",
    "\n",
    "ax[1][1].scatter(x, y, c=z_HIM, cmap='jet')\n",
    "ax[1][1].set_title('HIM')\n",
    "ax[1][1].set_xlabel('Day 1')\n",
    "ax[1][1].set_ylabel('Day 2')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_all.reshape(1, ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load country boundary data\n",
    "silhouette_scores_da_clip = silhouette_scores_da.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "silhouette_scores_da_clip.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "\n",
    "silhouette_scores_da_clip_IND = silhouette_scores_da_clip.rio.clip(country_boundary.geometry.apply(mapping), country_boundary.crs, drop=True)\n",
    "silhouette_scores_da_clip_HKK = silhouette_scores_da_clip.rio.clip(hkkh_boundary[hkkh_boundary.short_name=='hkk'].geometry.apply(mapping), hkkh_boundary[hkkh_boundary.short_name=='hkk'].crs, drop=True)\n",
    "silhouette_scores_da_clip_HIM = silhouette_scores_da_clip.rio.clip(hkkh_boundary[hkkh_boundary.short_name=='him'].geometry.apply(mapping), hkkh_boundary[hkkh_boundary.short_name=='him'].crs, drop=True)\n",
    "\n",
    "z_all = silhouette_scores_da_clip.mean(['lat', 'lon']).values\n",
    "z_IND = silhouette_scores_da_clip_IND.mean(['lat', 'lon']).values\n",
    "z_HKK = silhouette_scores_da_clip_HKK.mean(['lat', 'lon']).values\n",
    "z_HIM = silhouette_scores_da_clip_HIM.mean(['lat', 'lon']).values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(6,6), sharex=True, sharey=True)\n",
    "ax[0][0].scatter(x, y, c=z_all, cmap='jet')\n",
    "ax[0][0].set_title('All region')\n",
    "ax[0][0].set_xlabel('Day 1')\n",
    "ax[0][0].set_ylabel('Day 2')\n",
    "\n",
    "ax[0][1].scatter(x, y, c=z_IND, cmap='jet')\n",
    "ax[0][1].set_title('India')\n",
    "ax[0][1].set_xlabel('Day 1')\n",
    "ax[0][1].set_ylabel('Day 2')\n",
    "\n",
    "ax[1][0].scatter(x, y, c=z_HKK, cmap='jet')\n",
    "ax[1][0].set_title('HKK')\n",
    "ax[1][0].set_xlabel('Day 1')\n",
    "ax[1][0].set_ylabel('Day 2')\n",
    "\n",
    "ax[1][1].scatter(x, y, c=z_HIM, cmap='jet')\n",
    "ax[1][1].set_title('HIM')\n",
    "ax[1][1].set_xlabel('Day 1')\n",
    "ax[1][1].set_ylabel('Day 2')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(silhouette_scores_da.isel(iter = -1) - silhouette_scores_da.isel(iter = 0)).plot(vmin=0, vmax=0.1, extend='max', cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = silhouette_scores_da.mean(['lat','lon'])#.plot(hue='lon', add_legend=False)\n",
    "\n",
    "# sort a by value\n",
    "a = a.sortby(a).plot(hue='lon', add_legend=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(error_history_da.isel(iter = -1) - error_history_da.isel(iter = 0)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load country boundary data\n",
    "# mask_boundary = gpd.read_file(world_boundary_file, layer='ADM_1')\n",
    "# mask_boundary = mask_boundary[mask_boundary[\"GID_0\"].isin(['IND','NPL','BGD'])]\n",
    "\n",
    "# result_plot = result.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "# result_plot.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "# result_plot = result_plot.rio.clip(mask_boundary.geometry.apply(mapping), mask_boundary.crs, drop=True)\n",
    "\n",
    "result_plot = breakpoints\n",
    "\n",
    "\n",
    "plot_seasons_bk_results( result_plot, figsize=(10,5), cmaps=['summer', 'plasma_r'],\n",
    "                         lims=[[150,180],[245,300]], titles=['Monsoon Onset - Clustering', 'Monsoon Withdrawal - Clustering'],\n",
    "                         country_boundary=country_boundary, world_boundary=country_boundary)\n",
    "\n",
    "# plt.savefig(results_path_image, dpi=300, bbox_inches='tight', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(results_path_file) or overwrite_results:\n",
    "    \n",
    "#     result.attrs=dict(\n",
    "#             Description=\"Dataset with seasonal onset dates obtained with Radially Constrained Clustering\",\n",
    "#             Parameters=(\n",
    "\n",
    "#                 f\"Number of seasons: {n_seasons}\",\n",
    "#                 f\"Number of iterations: {n_iters}\",\n",
    "#                 f\"Learning rate: {learning_rate}\",\n",
    "#                 f\"Minimum length of seasons: {min_len}\",\n",
    "#                 f\"Clustering mode: {mode}\",\n",
    "#                 f\"Initializtion dates: {[day_of_year_to_date(x) for x in starting_bp]}\",\n",
    "        \n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     result.to_netcdf(results_path_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
